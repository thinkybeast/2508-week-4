{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgwB9Wll-vbc"
      },
      "source": [
        "# OpenAI Embeddings Lab\n",
        "\n",
        "This lab will help you understand how embeddings work and how to visualize semantic relationships between different pieces of text using OpenAI's embedding model.\n",
        "\n",
        "## Lab Structure\n",
        "\n",
        "The lab consists of 5 main exercises and 1 bonus exercise:\n",
        "\n",
        "1. **Generate Embeddings**: Learn how to use OpenAI's API to convert text into vector representations\n",
        "2. **Find Similar Sentences**: Apply embeddings to find semantically similar text\n",
        "3. **Find Different Sentences**: Identify the most semantically distant sentences\n",
        "4. **Compare to a New Sentence**: Given a new sentence, search already-embedded sentences for similar\n",
        "5. **Use a larger Corpus**: Test out your work with a larger corpus.\n",
        "\n",
        "**Bonus**: Reduce the dimensionality of your embeddings.\n",
        "\n",
        "## Tips\n",
        "\n",
        "- Read the OpenAI embeddings documentation carefully\n",
        "- Pay attention to the dimensionality of the vectors\n",
        "- Test with small examples first\n",
        "- Try modifying the corpus with your own sentences\n",
        "\n",
        "## Extension Ideas\n",
        "\n",
        "1. Try using a different embedding model\n",
        "2. Implement alternative similarity metrics\n",
        "3. Experiment with larger text corpora\n",
        "\n",
        "## Resources\n",
        "\n",
        "- [OpenAI Embeddings Documentation](https://platform.openai.com/docs/guides/embeddings)\n",
        "- [Cosine Similarity Explanation](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
        "\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "Let's begin by importing the necessary packages. We'll also set up our API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kQL5ZWl_cEP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()  # Load environment variables from .env file\n",
        "API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "print(API_KEY)\n",
        "\n",
        "client = OpenAI(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-LuOIzA_5W7"
      },
      "source": [
        "## Exercise 1: Generate Embeddings for the corpus\n",
        "\n",
        "Write a function that takes an array of strings and returns a dictionary with the sentences as keys and their embeddings as values. Use OpenAI's text-embedding-3-small model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at6qxuF--nSm"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog\",\n",
        "    \"A lazy dog sleeps in the sun\",\n",
        "    \"The brown fox is quick and clever\",\n",
        "    \"Dogs and cats are common pets\",\n",
        "    \"Foxes are wild animals that hunt\",\n",
        "]\n",
        "\n",
        "\n",
        "def generate_embeddings(texts):\n",
        "    \"\"\"\n",
        "    Generate embeddings for a list of text strings.\n",
        "\n",
        "    Arg: texts (list): List of strings to generate embeddings for\n",
        "    Returns: Dictionary with sentences as keys and embeddings as values\n",
        "    \"\"\"\n",
        "\n",
        "    embeddings = {}\n",
        "\n",
        "    response = client.embeddings.create(\n",
        "        input=texts,\n",
        "        model=\"text-embedding-3-small\"\n",
        "    )\n",
        "\n",
        "    for embedding_data in response.data:\n",
        "        embeddings[texts[embedding_data.index]] = embedding_data.embedding\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "embeddings = generate_embeddings(corpus)\n",
        "for sentence, embedding in embeddings.items():\n",
        "    print(f\"{sentence}: {embedding}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L1cd4isCCxM"
      },
      "source": [
        "## Exercise 2: Find the most similar pairs of sentences\n",
        "\n",
        "Write a function that finds and returns the most similar pair of sentences from the corpus based on their embedding similarities.\n",
        "\n",
        "You can utilize the `cosine_similarity` function from the previous lab:\n",
        "\n",
        "```python\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    dot = numpy.dot(vec1, vec2)\n",
        "    norm1 = numpy.linalg.norm(vec1)\n",
        "    norm2 = numpy.linalg.norm(vec2)\n",
        "    return dot / (norm1 * norm2)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e7o6wtjCOlP"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(vec1, vec2):\n",
        "    dot = numpy.dot(vec1, vec2)\n",
        "    norm1 = numpy.linalg.norm(vec1)\n",
        "    norm2 = numpy.linalg.norm(vec2)\n",
        "    return dot / (norm1 * norm2)\n",
        "\n",
        "\n",
        "def find_most_similar_pair(embeddings):\n",
        "    \"\"\"\n",
        "    Find the most similar pair of sentences in the corpus.\n",
        "\n",
        "    Args:\n",
        "        embeddings (dict): Dictionary with sentences as keys and embeddings as values\n",
        "\n",
        "    Returns: Dictionary with the most similar pair of sentences and their similarity score\n",
        "    \"\"\"\n",
        "\n",
        "    max_similarity = -1\n",
        "    most_similar_pair = {\n",
        "        \"sentence1\": \"\",\n",
        "        \"sentence2\": \"\",\n",
        "        \"similarity\": 0\n",
        "    }\n",
        "\n",
        "    # Compare each sentence with every other sentence\n",
        "    sentences = list(embeddings.keys())\n",
        "    for i, sentence1 in enumerate(sentences):\n",
        "        for j, sentence2 in enumerate(sentences[i + 1:], i + 1):\n",
        "            similarity = cosine_similarity(embeddings[sentence1], embeddings[sentence2])\n",
        "\n",
        "            if similarity > max_similarity:\n",
        "                max_similarity = similarity\n",
        "                most_similar_pair = {\n",
        "                    \"sentence1\": sentence1,\n",
        "                    \"sentence2\": sentence2,\n",
        "                    \"similarity\": similarity\n",
        "                }\n",
        "\n",
        "    print(\"Most similar pair:\")\n",
        "    print(f\"1. {most_similar_pair['sentence1']}\")\n",
        "    print(f\"2. {most_similar_pair['sentence2']}\")\n",
        "    print(f\"Similarity: {most_similar_pair['similarity']}\")\n",
        "    print()\n",
        "\n",
        "    return most_similar_pair\n",
        "\n",
        "\n",
        "sentence_pair = find_most_similar_pair(embeddings)\n",
        "print(sentence_pair)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSPR1V-XDKnp"
      },
      "source": [
        "## Exercise 3: Find the most semantically distant sentences\n",
        "\n",
        "Write a function that finds the pair of sentences with the lowest similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rShABJ59DSku"
      },
      "outputs": [],
      "source": [
        "def find_most_different_pair(embeddings):\n",
        "    \"\"\"\n",
        "    Find the most semantically different pair of sentences.\n",
        "\n",
        "    Args:\n",
        "        embeddings (dict): Dictionary with sentences as keys and embeddings as values\n",
        "\n",
        "    Returns: Dictionary with the most different pair of sentences and their similarity score\n",
        "    \"\"\"\n",
        "\n",
        "    min_similarity = 2  # Initialize to a value higher than the maximum possible similarity (1)\n",
        "    most_different_pair = {\n",
        "        \"sentence1\": \"\",\n",
        "        \"sentence2\": \"\",\n",
        "        \"similarity\": 0\n",
        "    }\n",
        "\n",
        "    # Compare each sentence with every other sentence\n",
        "    sentences = list(embeddings.keys())\n",
        "    for i, sentence1 in enumerate(sentences):\n",
        "        for j, sentence2 in enumerate(sentences[i + 1:], i + 1):\n",
        "            similarity = cosine_similarity(embeddings[sentence1], embeddings[sentence2])\n",
        "\n",
        "            if similarity < min_similarity:\n",
        "                min_similarity = similarity\n",
        "                most_different_pair = {\n",
        "                    \"sentence1\": sentence1,\n",
        "                    \"sentence2\": sentence2,\n",
        "                    \"similarity\": similarity\n",
        "                }\n",
        "\n",
        "    print(f\"Most different pair:\")\n",
        "    print(f\"1. {most_different_pair['sentence1']}\")\n",
        "    print(f\"2. {most_different_pair['sentence2']}\")\n",
        "    print(f\"Similarity: {most_different_pair['similarity']}\")\n",
        "    print()\n",
        "\n",
        "    return most_different_pair\n",
        "\n",
        "\n",
        "sentence_pair = find_most_different_pair(embeddings)\n",
        "print(sentence_pair)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4: Compare to a New Sentence\n",
        "\n",
        "Create a function that takes a new sentence and finds the most similar sentence from our corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_similar_to_new_sentence(new_sentence, embeddings):\n",
        "    \"\"\"\n",
        "    Find the most similar sentence to a new sentence.\n",
        "\n",
        "    Args:\n",
        "        new_sentence (str): The new sentence to find the most similar sentence for\n",
        "        embeddings (dict): Dictionary with sentences as keys and embeddings as values\n",
        "\n",
        "    Returns: Dictionary with the most similar sentence and its similarity score\n",
        "    \"\"\"\n",
        "    # Get embedding for new sentence\n",
        "    response = client.embeddings.create(\n",
        "        model=\"text-embedding-3-small\",\n",
        "        input=new_sentence\n",
        "    )\n",
        "    new_embedding = response.data[0].embedding\n",
        "\n",
        "    # Initialize variables to track most similar sentence\n",
        "    max_similarity = -1  # Initialize to value lower than minimum possible similarity (0)\n",
        "    most_similar_sentence = \"\"\n",
        "\n",
        "    # Compare new sentence embedding with all existing embeddings\n",
        "    for sentence, embedding in embeddings.items():\n",
        "        similarity = cosine_similarity(new_embedding, embedding)\n",
        "        \n",
        "        if similarity > max_similarity:\n",
        "            max_similarity = similarity\n",
        "            most_similar_sentence = sentence\n",
        "\n",
        "    print(f\"Most similar sentence to: '{new_sentence}'\")\n",
        "    print(f\"Is: '{most_similar_sentence}'\")\n",
        "    print(f\"Similarity: {max_similarity}\")\n",
        "    print()\n",
        "\n",
        "    return { \"sentence\": most_similar_sentence, \"similarity\": max_similarity }\n",
        "\n",
        "similar_sentence = find_similar_to_new_sentence(\"Gertrude is relaxing by the pool.\", embeddings)\n",
        "print(similar_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsAxoC6_EFQv"
      },
      "source": [
        "## Exercise 5: Use a larger corpus\n",
        "\n",
        "Now that we're comfortable with the basics, let's use a larger corpus. Find some long text...from wikipedia, blog posts, news sites, whatever interests you. Aim for approximately 4 pages of text.\n",
        "\n",
        "Split the text into sentences and embed the sentences as we did before.\n",
        "\n",
        "Finally, test out the functions you wrote above using this larger corpus.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1NfoOfQj6v6"
      },
      "outputs": [],
      "source": [
        "# TODO : Create embeddings with a larger corpus\n",
        "# TODO : Test above functions with larger corpus\n",
        "\n",
        "# Read the text file\n",
        "file_path = \"attention_is_all_you_need.txt\"\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Split the text into sentences\n",
        "sentences = text.split(\".\")  # Splitting by periods (basic sentence splitting)\n",
        "\n",
        "# Filter out very short sentences; they don't work well for this exercise\n",
        "sentences = [sentence.strip() for sentence in sentences if len(sentence.strip()) > 40]\n",
        "\n",
        "article_embeddings = generate_embeddings(sentences)\n",
        "print(f\"Generated embeddings for {len(article_embeddings)} sentences.\")\n",
        "\n",
        "print('------------------------------------')\n",
        "\n",
        "print(\"Finding most similar pair in large corpus...\")\n",
        "similar_pair = find_most_similar_pair(article_embeddings)\n",
        "print(similar_pair)\n",
        "\n",
        "print('------------------------------------')\n",
        "\n",
        "print(\"Finding most different pair in large corpus...\")\n",
        "different_pair = find_most_different_pair(article_embeddings)\n",
        "print(different_pair)\n",
        "\n",
        "print('------------------------------------')\n",
        "\n",
        "print(\"Finding sentence similar to new sentence in large corpus...\")\n",
        "similar_sentence = find_similar_to_new_sentence(\"The transformer architecture relies entirely on self-attention mechanisms.\", article_embeddings)\n",
        "print(similar_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqUsVsJhkNOv"
      },
      "source": [
        "## Bonus: Reduce Dimensionality\n",
        "\n",
        "The project you're working on is running short on storage space and money. You've been tasked with reducing the dimensionality of the embeddings you've generated. 1536 is simply too large. You've been given these requirements:\n",
        "\n",
        "- Reduce the dimensionality of the embeddings to 256.\n",
        "- DO NOT re-generate the embeddings. We can't afford the tokens!\n",
        "\n",
        "You need to figure out how this is possible and write the code to do so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Source: https://platform.openai.com/docs/guides/embeddings#:~:text=Reducing%20embedding%20dimensions\n",
        "\n",
        "def normalize_l2(x):\n",
        "    x = numpy.array(x)\n",
        "    if x.ndim == 1:\n",
        "        norm = numpy.linalg.norm(x)\n",
        "        if norm == 0:\n",
        "            return x\n",
        "        return x / norm\n",
        "    else:\n",
        "        norm = numpy.linalg.norm(x, 2, axis=1, keepdims=True)\n",
        "        return numpy.where(norm == 0, x, x / norm)\n",
        "\n",
        "def reduce_and_normalize_embeddings(embeddings_dict, target_dim=256):\n",
        "    \"\"\"\n",
        "    Reduce embeddings to target_dim dimensions and L2 normalize them.\n",
        "\n",
        "    Args:\n",
        "        embeddings_dict (dict): {sentence: embedding_vector}\n",
        "        target_dim (int): number of dimensions to keep\n",
        "    \n",
        "    Returns:\n",
        "        dict: {sentence: reduced_normalized_embedding}\n",
        "    \"\"\"\n",
        "    return {\n",
        "        sentence: normalize_l2(embedding[:target_dim])\n",
        "        for sentence, embedding in embeddings_dict.items()\n",
        "    }\n",
        "\n",
        "print(\"Original embedding dimension:\")\n",
        "print(len(next(iter(article_embeddings.items()))[1]))  # Length of the first embedding vector\n",
        "\n",
        "reduced_embeddings = reduce_and_normalize_embeddings(article_embeddings, target_dim=256)\n",
        "\n",
        "print(\"Reduced embedding dimension:\")\n",
        "print(len(next(iter(reduced_embeddings.items()))[1]))  # Length of the reduced embedding\n",
        "\n",
        "print(\"\\nMost similar pair in reduced embeddings:\")\n",
        "print(find_most_similar_pair(reduced_embeddings))\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
