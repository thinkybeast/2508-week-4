{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgwB9Wll-vbc"
      },
      "source": [
        "# OpenAI Embeddings Lab\n",
        "\n",
        "This lab will help you understand how embeddings work and how to visualize semantic relationships between different pieces of text using OpenAI's embedding model.\n",
        "\n",
        "## Lab Structure\n",
        "\n",
        "The lab consists of 5 main exercises and 1 bonus exercise:\n",
        "\n",
        "1. **Generate Embeddings**: Learn how to use OpenAI's API to convert text into vector representations\n",
        "2. **Find Similar Sentences**: Apply embeddings to find semantically similar text\n",
        "3. **Find Different Sentences**: Identify the most semantically distant sentences\n",
        "4. **Compare to a New Sentence**: Given a new sentence, search already-embedded sentences for similar\n",
        "5. **Use a larger Corpus**: Test out your work with a larger corpus.\n",
        "\n",
        "**Bonus**: Reduce the dimensionality of your embeddings.\n",
        "\n",
        "## Tips\n",
        "\n",
        "- Read the OpenAI embeddings documentation carefully\n",
        "- Pay attention to the dimensionality of the vectors\n",
        "- Test with small examples first\n",
        "- Try modifying the corpus with your own sentences\n",
        "\n",
        "## Extension Ideas\n",
        "\n",
        "1. Try using a different embedding model\n",
        "2. Implement alternative similarity metrics\n",
        "3. Experiment with larger text corpora\n",
        "\n",
        "## Resources\n",
        "\n",
        "- [OpenAI Embeddings Documentation](https://platform.openai.com/docs/guides/embeddings)\n",
        "- [Cosine Similarity Explanation](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
        "\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "Let's begin by importing the necessary packages. We'll also set up our API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kQL5ZWl_cEP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()  # Load environment variables from .env file\n",
        "API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "print(API_KEY)\n",
        "\n",
        "client = OpenAI(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-LuOIzA_5W7"
      },
      "source": [
        "## Exercise 1: Generate Embeddings for the corpus\n",
        "\n",
        "Write a function that takes an array of strings and returns a dictionary with the sentences as keys and their embeddings as values. Use OpenAI's text-embedding-3-small model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at6qxuF--nSm"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog\",\n",
        "    \"A lazy dog sleeps in the sun\",\n",
        "    \"The brown fox is quick and clever\",\n",
        "    \"Dogs and cats are common pets\",\n",
        "    \"Foxes are wild animals that hunt\",\n",
        "]\n",
        "\n",
        "\n",
        "def generate_embeddings(texts):\n",
        "    \"\"\"\n",
        "    Generate embeddings for a list of text strings.\n",
        "\n",
        "    Arg: texts (list): List of strings to generate embeddings for\n",
        "    Returns: Dictionary with sentences as keys and embeddings as values\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO\n",
        "\n",
        "embeddings = generate_embeddings(corpus)\n",
        "for sentence, embedding in embeddings.items():\n",
        "    print(f\"{sentence}: {embedding}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L1cd4isCCxM"
      },
      "source": [
        "## Exercise 2: Find the most similar pairs of sentences\n",
        "\n",
        "Write a function that finds and returns the most similar pair of sentences from the corpus based on their embedding similarities.\n",
        "\n",
        "You can utilize the `cosine_similarity` function from the previous lab:\n",
        "\n",
        "```python\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    dot = numpy.dot(vec1, vec2)\n",
        "    norm1 = numpy.linalg.norm(vec1)\n",
        "    norm2 = numpy.linalg.norm(vec2)\n",
        "    return dot / (norm1 * norm2)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e7o6wtjCOlP"
      },
      "outputs": [],
      "source": [
        "def find_most_similar_pair(embeddings):\n",
        "    \"\"\"\n",
        "    Find the most similar pair of sentences in the corpus.\n",
        "\n",
        "    Args:\n",
        "        embeddings (dict): Dictionary with sentences as keys and embeddings as values\n",
        "\n",
        "    Returns: Dictionary with the most similar pair of sentences and their similarity score\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "sentence_pair = find_most_similar_pair(embeddings)\n",
        "print(sentence_pair)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSPR1V-XDKnp"
      },
      "source": [
        "## Exercise 3: Find the most semantically distant sentences\n",
        "\n",
        "Write a function that finds the pair of sentences with the lowest similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rShABJ59DSku"
      },
      "outputs": [],
      "source": [
        "def find_most_different_pair(embeddings):\n",
        "    \"\"\"\n",
        "    Find the most semantically different pair of sentences.\n",
        "\n",
        "    Args:\n",
        "        embeddings (dict): Dictionary with sentences as keys and embeddings as values\n",
        "\n",
        "    Returns: Dictionary with the most different pair of sentences and their similarity score\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "sentence_pair = find_most_different_pair(embeddings)\n",
        "print(sentence_pair)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4: Compare to a New Sentence\n",
        "\n",
        "Create a function that takes a new sentence and finds the most similar sentence from our corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_similar_to_new_sentence(new_sentence, embeddings):\n",
        "    \"\"\"\n",
        "    Find the most similar sentence to a new sentence.\n",
        "\n",
        "    Args:\n",
        "        new_sentence (str): The new sentence to find the most similar sentence for\n",
        "        embeddings (dict): Dictionary with sentences as keys and embeddings as values\n",
        "\n",
        "    Returns: Dictionary with the most similar sentence and its similarity score\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO\n",
        "\n",
        "    pass\n",
        "\n",
        "similar_sentence = find_similar_to_new_sentence(\"Gertrude is relaxing by the pool.\", embeddings)\n",
        "print(similar_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsAxoC6_EFQv"
      },
      "source": [
        "## Exercise 5: Use a larger corpus\n",
        "\n",
        "Now that we're comfortable with the basics, let's use a larger corpus. Find some long text...from wikipedia, blog posts, news sites, whatever interests you. Aim for approximately 4 pages of text.\n",
        "\n",
        "Split the text into sentences and embed the sentences as we did before.\n",
        "\n",
        "Finally, test out the functions you wrote above using this larger corpus.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1NfoOfQj6v6"
      },
      "outputs": [],
      "source": [
        "# TODO : Create embeddings with a larger corpus\n",
        "# TODO : Test above functions with larger corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqUsVsJhkNOv"
      },
      "source": [
        "## Bonus: Reduce Dimensionality\n",
        "\n",
        "The project you're working on is running short on storage space and money. You've been tasked with reducing the dimensionality of the embeddings you've generated. 1536 is simply too large. You've been given these requirements:\n",
        "\n",
        "- Reduce the dimensionality of the embeddings to 256.\n",
        "- DO NOT re-generate the embeddings. We can't afford the tokens!\n",
        "\n",
        "You need to figure out how this is possible and write the code to do so."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
