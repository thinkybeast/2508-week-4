{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04379ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "print(API_KEY)\n",
    "\n",
    "MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea28414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenManager:\n",
    "    def __init__(self, model, max_tokens):\n",
    "        self.encoding = tiktoken.encoding_for_model(model)\n",
    "        self.max_tokens = max_tokens\n",
    "        self.tokens_used = 0\n",
    "\n",
    "    def exceeds_limit(self):\n",
    "        return self.tokens_used >= self.max_tokens\n",
    "\n",
    "    def add_tokens(self, messages):\n",
    "        num_tokens = 0\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "\n",
    "        for message in messages:\n",
    "            num_tokens += tokens_per_message\n",
    "            for key, value in message.items():\n",
    "                num_tokens += len(self.encoding.encode(value))\n",
    "                if key == 'name':\n",
    "                    num_tokens += tokens_per_name\n",
    "\n",
    "        num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "\n",
    "        self.tokens_used += num_tokens\n",
    "\n",
    "    def reset(self):\n",
    "        self.tokens_used = 0\n",
    "\n",
    "\n",
    "class Message:\n",
    "    def __init__(self, role, content):\n",
    "        self.role = role\n",
    "        self.content = content\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {'role': self.role, 'content': self.content}\n",
    "\n",
    "\n",
    "class ChatHistory:\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def add(self, message):\n",
    "        self.messages.append(message)\n",
    "\n",
    "    def to_list(self):\n",
    "        return [msg.to_dict() for msg in self.messages]\n",
    "\n",
    "    def clear(self):\n",
    "      self.messages = []\n",
    "\n",
    "\n",
    "class ChatManager:\n",
    "    def __init__(self, model, system_prompt):\n",
    "        self.model = model\n",
    "        self.history = ChatHistory()\n",
    "        self.system_prompt = system_prompt\n",
    "        self.history.add(Message('developer', system_prompt))\n",
    "        self.client = OpenAI(api_key=API_KEY)\n",
    "        self.token_manager = TokenManager(model, 300) # Low token limit for testing\n",
    "\n",
    "    def get_response(self):\n",
    "        response = self.client.responses.create(\n",
    "            model=self.model,\n",
    "            input=self.history.to_list()\n",
    "        )\n",
    "        return response.output_text\n",
    "    \n",
    "    def summarize_memory(self, max_summary_tokens=200):\n",
    "        # Exclude users most recent message from summarization\n",
    "        previous_messages = self.history.to_list()[:-1]\n",
    "        formatted_messages = ''.join([ f'{msg['role']}: {msg['content']}\\n\\n' for msg in previous_messages ])\n",
    "\n",
    "        summary_prompt = f\"\"\"\n",
    "Please summarize the following conversation in\n",
    "{max_summary_tokens} tokens or less. Focus on key topics, decisions, and\n",
    "important context that should be remembered:\n",
    "{formatted_messages}\n",
    "\"\"\"\n",
    "        summary_response = self.client.responses.create(\n",
    "            model=self.model,\n",
    "            input=summary_prompt\n",
    "        )\n",
    "        \n",
    "        return summary_response.output_text\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Welcome to ChatGPT-like Application!\")\n",
    "        print(\"Type 'exit' or 'quit' to end the conversation.\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        while True:\n",
    "            user_input = input('You: ')\n",
    "            if user_input.lower() in ['exit', 'quit']:\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "        \n",
    "            print(f'You: {user_input}')\n",
    "\n",
    "            self.history.add(Message('user', user_input))\n",
    "            self.token_manager.add_tokens(self.history.to_list())\n",
    "\n",
    "            if self.token_manager.exceeds_limit():\n",
    "                print(\"Conversation limit reached. One moment while I summarize the conversation so far.\")\n",
    "                print(\"Clearing conversation history...\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "                summary = self.summarize_memory()\n",
    "                last_user_message = self.history.to_list()[-1]\n",
    "                self.history.clear()\n",
    "                self.token_manager.reset()\n",
    "                self.history.add(Message('developer', self.system_prompt))\n",
    "                self.history.add(Message('developer', f'Here\\'s a summary of the conversation up to this point: {summary}'))\n",
    "                self.history.add(Message(last_user_message['role'], last_user_message['content']))\n",
    "\n",
    "            print(\"Thinking...\", end=\"\\r\")\n",
    "\n",
    "            response_text = self.get_response()\n",
    "            print(\"Assistant:\", response_text)\n",
    "\n",
    "            self.history.add(Message('assistant', response_text))\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a helpful assistant.\"\n",
    "chat = ChatManager(MODEL, SYSTEM_PROMPT)\n",
    "chat.run()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
