{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6wVZROPMl2P"
      },
      "source": [
        "# API Key & Model Selection\n",
        "\n",
        "The following cell lets you test that you're API key is accessible. To add your API key, follow instructions in `README`.\n",
        "\n",
        "> ðŸ’¡ Remember! This cell needs to be ran before you can run any other cells that utilize the `API_KEY` variable. If you reset the runtime, you'll need to run this cell again.\n",
        "\n",
        "We'll also create a constant to choose our model here so don't have to repeat it throughout every cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qhvm_n_I2yv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()  # Load environment variables from .env file\n",
        "API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "print(API_KEY)\n",
        "\n",
        "MODEL = 'gpt-4o-mini'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-JsNSyDOCVi"
      },
      "source": [
        "# Getting Started\n",
        "\n",
        "This code snippet is from the [Text generation and prompting](https://platform.openai.com/docs/guides/text?api-mode=responses) API reference of the OpenAI documentation. Try it out to make sure everything is working so far."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuNjJ7hnOJhe"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=MODEL,\n",
        "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa5Mw4mMOwgw"
      },
      "source": [
        "# Part 1: Create a Chat Loop\n",
        "\n",
        "Use the [Text generation and prompting](https://platform.openai.com/docs/guides/text?api-mode=responses) guide to complete the following todos.\n",
        "\n",
        "> ðŸ’¡ If you navigate to the documentation yourself, make sure that you're using the \"Responses\" API, not \"Chat Completions\". Both work, but \"Responses\" is newer, and it's what we'll use in examples and solutions.\n",
        "\n",
        "<details>\n",
        "<summary> ðŸ‘‰ Hints! </summary>\n",
        "\n",
        "- You'll need to study the examples to see how to include multiple messages, or \"conversation state\".\n",
        "- The `input` function works in Jupyter Notebooks just like it does in a `.py` file to get input from the user.\n",
        "- Your `chat` function will need to run in a loop. Make sure to provide a way for the user to exit the loop.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doEkoleWPFKU"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "def get_response(history):\n",
        "    response = client.responses.create(\n",
        "        model=MODEL,\n",
        "        input=history,\n",
        "    )\n",
        "    return response.output_text\n",
        "\n",
        "\n",
        "def chat():\n",
        "    \"\"\"Main chat loop.\"\"\"\n",
        "    print(\"Welcome to ChatGPT-like Application!\")\n",
        "    print(\"Type 'exit' or 'quit' to end the conversation.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    history = []\n",
        "\n",
        "    # Add a system message to set the assistant's behavior\n",
        "    system_msg = { 'role': 'developer', 'content': 'You are a helpful assistant.' }\n",
        "    history.append(system_msg)\n",
        "\n",
        "    while True:\n",
        "        # Get user input\n",
        "        user_input = input('You: ')\n",
        "\n",
        "        # Check if user wants to exit\n",
        "        if user_input.lower() in ['exit', 'quit']:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "    \n",
        "        print(f'You: {user_input}')\n",
        "\n",
        "        # Add user message to history\n",
        "        user_msg = { 'role': 'user', 'content': user_input }\n",
        "        history.append(user_msg)\n",
        "\n",
        "        # Display thinking indicator\n",
        "        print(\"Thinking...\", end=\"\\r\")\n",
        "\n",
        "        # Generate and display response\n",
        "        response = get_response(history)\n",
        "\n",
        "        print(\"Assistant:\", response)\n",
        "\n",
        "        # Add assistant message to history\n",
        "        assistant_msg = { 'role': 'assistant', 'content': response }\n",
        "        history.append(assistant_msg)\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YukGT6iUDOs"
      },
      "source": [
        "# Part 2: Add Classes to Your Program\n",
        "\n",
        "Managing the messages and history of our conversation is a bit clumsy. Create some classes with whatever methods necessary to make our code more declarative. Use these suggestions or take your own approach:\n",
        "\n",
        "- `Message`: Have a role and content. Takes the form of a `dict` object for API calls.\n",
        "- `ChatHistory`: Maintains an array of `Message` objects. Takes the form of a `list` for API calls.\n",
        "- `ChatManager`: Orchestrates the interaction utilizing `Message` and `ChatHistory` classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcMgsFuSWAZ5"
      },
      "outputs": [],
      "source": [
        "class Message:\n",
        "    def __init__(self, role, content):\n",
        "        self.role = role\n",
        "        self.content = content\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {'role': self.role, 'content': self.content}\n",
        "\n",
        "\n",
        "class ChatHistory:\n",
        "    def __init__(self):\n",
        "        self.messages = []\n",
        "\n",
        "    def add(self, message):\n",
        "        self.messages.append(message)\n",
        "\n",
        "    def to_list(self):\n",
        "        return [msg.to_dict() for msg in self.messages]\n",
        "\n",
        "\n",
        "class ChatManager:\n",
        "    def __init__(self, model, system_prompt):\n",
        "        self.model = model\n",
        "        self.history = ChatHistory()\n",
        "        self.history.add(Message('developer', system_prompt))\n",
        "        self.client = OpenAI(api_key=API_KEY)\n",
        "\n",
        "    def get_response(self):\n",
        "        response = self.client.responses.create(\n",
        "            model=self.model,\n",
        "            input=self.history.to_list()\n",
        "        )\n",
        "        return response.output_text\n",
        "\n",
        "    def run(self):\n",
        "        print(\"Welcome to ChatGPT-like Application!\")\n",
        "        print(\"Type 'exit' or 'quit' to end the conversation.\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        while True:\n",
        "            user_input = input('You: ')\n",
        "            if user_input.lower() in ['exit', 'quit']:\n",
        "                print(\"Goodbye!\")\n",
        "                break\n",
        "        \n",
        "            print(f'You: {user_input}')\n",
        "\n",
        "            self.history.add(Message('user', user_input))\n",
        "            print(\"Thinking...\", end=\"\\r\")\n",
        "\n",
        "            response_text = self.get_response()\n",
        "            print(\"Assistant:\", response_text)\n",
        "\n",
        "            self.history.add(Message('assistant', response_text))\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "\n",
        "SYSTEM_PROMPT = \"You are a helpful assistant.\"\n",
        "chat = ChatManager(MODEL, SYSTEM_PROMPT)\n",
        "chat.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EpRBwY1YnNa"
      },
      "source": [
        "# Part 3: Token Management\n",
        "\n",
        "When making API calls, we're charged per-token. Let's make sure that our user can't surpass a certain number of tokens in their message.\n",
        "\n",
        "First, skim this information on [Managing Tokens](https://platform.openai.com/docs/advanced-usage#managing-tokens). Towards the end of this section, they mention the Python library [tiktoken](https://github.com/openai/tiktoken).\n",
        "\n",
        "Using the documentation for tiktoken (the README file of the tiktoken GitHub repo), and the [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb), implement a feature that stops conversations from exceeding a certain token limit. Make sure to test that the result you're getting from `tiktoken` is close to the actual tokens being used, which you can find in the API response.\n",
        "\n",
        "> ðŸ’¡ You'll need to use `poetry add tiktoken` to update your project with the new library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c6VhgGfaHZd"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "class TokenManager:\n",
        "    def __init__(self, model, max_tokens):\n",
        "        self.encoding = tiktoken.encoding_for_model(model)\n",
        "        self.max_tokens = max_tokens\n",
        "        self.tokens_used = 0\n",
        "\n",
        "    def exceeds_limit(self):\n",
        "        return self.tokens_used >= self.max_tokens\n",
        "\n",
        "    def add_tokens(self, messages):\n",
        "        num_tokens = 0\n",
        "        tokens_per_message = 3\n",
        "        tokens_per_name = 1\n",
        "\n",
        "        for message in messages:\n",
        "            num_tokens += tokens_per_message\n",
        "            for key, value in message.items():\n",
        "                num_tokens += len(self.encoding.encode(value))\n",
        "                if key == 'name':\n",
        "                    num_tokens += tokens_per_name\n",
        "\n",
        "        num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
        "\n",
        "        self.tokens_used += num_tokens\n",
        "\n",
        "    def reset(self):\n",
        "        self.tokens_used = 0\n",
        "\n",
        "\n",
        "# No changes to `Message` class\n",
        "class Message:\n",
        "    def __init__(self, role, content):\n",
        "        self.role = role\n",
        "        self.content = content\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {'role': self.role, 'content': self.content}\n",
        "\n",
        "\n",
        "# Only change to `ChatHistory` was adding a `clear` method\n",
        "class ChatHistory:\n",
        "    def __init__(self):\n",
        "        self.messages = []\n",
        "\n",
        "    def add(self, message):\n",
        "        self.messages.append(message)\n",
        "\n",
        "    def to_list(self):\n",
        "        return [msg.to_dict() for msg in self.messages]\n",
        "\n",
        "    def clear(self):\n",
        "      self.messages = []\n",
        "\n",
        "\n",
        "class ChatManager:\n",
        "    def __init__(self, model, system_prompt):\n",
        "        self.model = model\n",
        "        self.history = ChatHistory()\n",
        "        self.system_prompt = system_prompt\n",
        "        self.history.add(Message('developer', system_prompt))\n",
        "        self.client = OpenAI(api_key=API_KEY)\n",
        "        self.token_manager = TokenManager(model, 300) # Low token limit for testing\n",
        "\n",
        "    def get_response(self):\n",
        "        response = self.client.responses.create(\n",
        "            model=self.model,\n",
        "            input=self.history.to_list()\n",
        "        )\n",
        "        return response.output_text\n",
        "\n",
        "    def run(self):\n",
        "        print(\"Welcome to ChatGPT-like Application!\")\n",
        "        print(\"Type 'exit' or 'quit' to end the conversation.\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        while True:\n",
        "            user_input = input('You: ')\n",
        "            if user_input.lower() in ['exit', 'quit']:\n",
        "                print(\"Goodbye!\")\n",
        "                break\n",
        "        \n",
        "            print(f'You: {user_input}')\n",
        "\n",
        "            self.history.add(Message('user', user_input))\n",
        "            self.token_manager.add_tokens(self.history.to_list())\n",
        "\n",
        "            if self.token_manager.exceeds_limit():\n",
        "                print(\"Conversation limit reached. Please start a new conversation.\")\n",
        "                print(\"Clearing conversation history...\")\n",
        "                print(\"-\" * 50)\n",
        "                print(\"Welcome to ChatGPT-like Application!\")\n",
        "                print(\"Type 'exit' or 'quit' to end the conversation.\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "                self.history.clear()\n",
        "                self.token_manager.reset()\n",
        "                self.history.add(Message('developer', self.system_prompt))\n",
        "                continue\n",
        "\n",
        "            print(\"Thinking...\", end=\"\\r\")\n",
        "\n",
        "            response_text = self.get_response()\n",
        "            print(\"Assistant:\", response_text)\n",
        "\n",
        "            self.history.add(Message('assistant', response_text))\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "\n",
        "SYSTEM_PROMPT = \"You are a helpful assistant.\"\n",
        "chat = ChatManager(MODEL, SYSTEM_PROMPT)\n",
        "chat.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9zd3Aluh3DJ"
      },
      "source": [
        "# Bonus Ideas\n",
        "\n",
        "If you have extra time, here are some ideas:\n",
        "\n",
        "- **Customize the system prompt**. Allow the user to either select some attributes, like 'formal' vs 'informal', or let them set their own system prompt.\n",
        "\n",
        "- **Save past conversations to a file.** Create a directory that stores conversations once they've ended, along with meta-data like the date and time of the conversation.\n",
        "\n",
        "- **Implement a 'help' command.** Give the user a way to access a help menu with more information. You could allow for other commands, like checking token limits.\n",
        "\n",
        "- **Timeout the Chatbot**. After a certain amount of inactivity, automatically end the conversation.\n",
        "\n",
        "- **Error Handling**. We don't have any error handling right now. Look into possible responses from the OpenAI API and handle them gracefully. You can view information about [the response object here](https://platform.openai.com/docs/api-reference/responses/object)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
